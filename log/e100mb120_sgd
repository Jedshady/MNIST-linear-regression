###########################################
#epoch number: 100
#minibatch size: 120
#precision type: full precision
#gradients update rule: SGD
###########################################
epoch  1 : iter   50 : loss 2.359447 : vld 0.855357
epoch  1 : iter  100 : loss 2.326182 : vld 0.732378
epoch  1 : iter  150 : loss 2.291967 : vld 0.595067
epoch  1 : iter  200 : loss 2.260130 : vld 0.499750
epoch  1 : iter  250 : loss 2.226550 : vld 0.425262
epoch  1 : iter  300 : loss 2.198523 : vld 0.375604
epoch  1 : iter  350 : loss 2.163891 : vld 0.345442
epoch  1 : iter  400 : loss 2.135281 : vld 0.324946
epoch  1 : iter  450 : loss 2.107248 : vld 0.307115
epoch  2 : iter   50 : loss 2.073642 : vld 0.295284
epoch  2 : iter  100 : loss 2.046835 : vld 0.288952
epoch  2 : iter  150 : loss 2.017552 : vld 0.287285
epoch  2 : iter  200 : loss 1.991683 : vld 0.280787
epoch  2 : iter  250 : loss 1.959549 : vld 0.275954
epoch  2 : iter  300 : loss 1.936617 : vld 0.270288
epoch  2 : iter  350 : loss 1.907410 : vld 0.267289
epoch  2 : iter  400 : loss 1.889152 : vld 0.263289
epoch  2 : iter  450 : loss 1.861530 : vld 0.261790
epoch  3 : iter   50 : loss 1.834560 : vld 0.251791
epoch  3 : iter  100 : loss 1.804666 : vld 0.248792
epoch  3 : iter  150 : loss 1.776937 : vld 0.247292
epoch  3 : iter  200 : loss 1.762505 : vld 0.243793
epoch  3 : iter  250 : loss 1.729210 : vld 0.241793
epoch  3 : iter  300 : loss 1.704870 : vld 0.240793
epoch  3 : iter  350 : loss 1.686494 : vld 0.238794
epoch  3 : iter  400 : loss 1.675311 : vld 0.234628
epoch  3 : iter  450 : loss 1.633802 : vld 0.235127
epoch  4 : iter   50 : loss 1.623802 : vld 0.237794
epoch  4 : iter  100 : loss 1.593377 : vld 0.235294
epoch  4 : iter  150 : loss 1.574007 : vld 0.234461
epoch  4 : iter  200 : loss 1.552332 : vld 0.233628
epoch  4 : iter  250 : loss 1.530313 : vld 0.230962
epoch  4 : iter  300 : loss 1.505359 : vld 0.230128
epoch  4 : iter  350 : loss 1.495112 : vld 0.227629
epoch  4 : iter  400 : loss 1.473356 : vld 0.226462
epoch  4 : iter  450 : loss 1.454694 : vld 0.224963
epoch  5 : iter   50 : loss 1.425759 : vld 0.230795
epoch  5 : iter  100 : loss 1.419190 : vld 0.227295
epoch  5 : iter  150 : loss 1.390350 : vld 0.225462
epoch  5 : iter  200 : loss 1.380576 : vld 0.225629
epoch  5 : iter  250 : loss 1.362728 : vld 0.224629
epoch  5 : iter  300 : loss 1.352208 : vld 0.222296
epoch  5 : iter  350 : loss 1.330776 : vld 0.217797
epoch  5 : iter  400 : loss 1.311842 : vld 0.217464
epoch  5 : iter  450 : loss 1.313905 : vld 0.215131
epoch  6 : iter   50 : loss 1.290852 : vld 0.209298
epoch  6 : iter  100 : loss 1.256378 : vld 0.208132
epoch  6 : iter  150 : loss 1.267769 : vld 0.206966
epoch  6 : iter  200 : loss 1.250974 : vld 0.204299
epoch  6 : iter  250 : loss 1.230268 : vld 0.203466
epoch  6 : iter  300 : loss 1.201679 : vld 0.202133
epoch  6 : iter  350 : loss 1.196961 : vld 0.200633
epoch  6 : iter  400 : loss 1.179680 : vld 0.198467
epoch  6 : iter  450 : loss 1.176910 : vld 0.196634
epoch  7 : iter   50 : loss 1.156870 : vld 0.200800
epoch  7 : iter  100 : loss 1.150222 : vld 0.199633
epoch  7 : iter  150 : loss 1.133219 : vld 0.197134
epoch  7 : iter  200 : loss 1.123670 : vld 0.195134
epoch  7 : iter  250 : loss 1.111041 : vld 0.194801
epoch  7 : iter  300 : loss 1.117068 : vld 0.194134
epoch  7 : iter  350 : loss 1.096177 : vld 0.191801
epoch  7 : iter  400 : loss 1.084177 : vld 0.190968
epoch  7 : iter  450 : loss 1.072410 : vld 0.189802
epoch  8 : iter   50 : loss 1.065352 : vld 0.187135
epoch  8 : iter  100 : loss 1.042025 : vld 0.186469
epoch  8 : iter  150 : loss 1.044849 : vld 0.184803
epoch  8 : iter  200 : loss 1.027544 : vld 0.183969
epoch  8 : iter  250 : loss 1.030278 : vld 0.183803
epoch  8 : iter  300 : loss 1.020216 : vld 0.182970
epoch  8 : iter  350 : loss 1.010363 : vld 0.181136
epoch  8 : iter  400 : loss 1.003383 : vld 0.179970
