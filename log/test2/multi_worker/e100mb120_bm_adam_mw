###########################################
#epoch number: 100
#minibatch size: 120
#precision type: full precision
#training mode: multi workers
#gradients update rule: BM_Adam
###########################################
epoch  1 : iter   10 : loss 1.923212 : vld 0.214464
epoch  1 : iter   20 : loss 1.071658 : vld 0.171305
epoch  1 : iter   30 : loss 0.686704 : vld 0.137644
epoch  1 : iter   40 : loss 0.501666 : vld 0.117314
epoch  1 : iter   50 : loss 0.456193 : vld 0.107982
epoch  1 : iter   60 : loss 0.395778 : vld 0.100650
epoch  1 : iter   70 : loss 0.378925 : vld 0.095484
epoch  1 : iter   80 : loss 0.378116 : vld 0.092818
epoch  1 : iter   90 : loss 0.359496 : vld 0.090652
epoch  2 : iter   10 : loss 0.374215 : vld 0.085986
epoch  2 : iter   20 : loss 0.325358 : vld 0.086486
epoch  2 : iter   30 : loss 0.323463 : vld 0.084653
epoch  2 : iter   40 : loss 0.326447 : vld 0.082986
epoch  2 : iter   50 : loss 0.318454 : vld 0.082653
epoch  2 : iter   60 : loss 0.331928 : vld 0.078154
epoch  2 : iter   70 : loss 0.330869 : vld 0.077987
epoch  2 : iter   80 : loss 0.317520 : vld 0.075154
epoch  2 : iter   90 : loss 0.312815 : vld 0.074821
epoch  3 : iter   10 : loss 0.296283 : vld 0.076654
epoch  3 : iter   20 : loss 0.289297 : vld 0.073988
epoch  3 : iter   30 : loss 0.310620 : vld 0.074821
epoch  3 : iter   40 : loss 0.281431 : vld 0.072321
epoch  3 : iter   50 : loss 0.293686 : vld 0.071821
epoch  3 : iter   60 : loss 0.275398 : vld 0.071155
epoch  3 : iter   70 : loss 0.295008 : vld 0.069488
epoch  3 : iter   80 : loss 0.290370 : vld 0.069155
epoch  3 : iter   90 : loss 0.260906 : vld 0.064823
epoch  4 : iter   10 : loss 0.279431 : vld 0.063823
epoch  4 : iter   20 : loss 0.253758 : vld 0.060657
epoch  4 : iter   30 : loss 0.256457 : vld 0.062156
epoch  4 : iter   40 : loss 0.255168 : vld 0.061990
epoch  4 : iter   50 : loss 0.272448 : vld 0.064656
epoch  4 : iter   60 : loss 0.244746 : vld 0.059657
epoch  4 : iter   70 : loss 0.238672 : vld 0.059157
epoch  4 : iter   80 : loss 0.259012 : vld 0.057824
epoch  4 : iter   90 : loss 0.254378 : vld 0.058657
epoch  5 : iter   10 : loss 0.236547 : vld 0.053158
epoch  5 : iter   20 : loss 0.234596 : vld 0.055157
epoch  5 : iter   30 : loss 0.240413 : vld 0.055657
epoch  5 : iter   40 : loss 0.228646 : vld 0.052658
epoch  5 : iter   50 : loss 0.223177 : vld 0.055157
epoch  5 : iter   60 : loss 0.219536 : vld 0.051491
epoch  5 : iter   70 : loss 0.232697 : vld 0.054324
epoch  5 : iter   80 : loss 0.221585 : vld 0.051158
epoch  5 : iter   90 : loss 0.241977 : vld 0.053824
epoch  6 : iter   10 : loss 0.221239 : vld 0.051991
epoch  6 : iter   20 : loss 0.210845 : vld 0.050992
epoch  6 : iter   30 : loss 0.220068 : vld 0.049992
epoch  6 : iter   40 : loss 0.204276 : vld 0.050992
epoch  6 : iter   50 : loss 0.210862 : vld 0.051658
epoch  6 : iter   60 : loss 0.206147 : vld 0.052491
epoch  6 : iter   70 : loss 0.211261 : vld 0.050992
epoch  6 : iter   80 : loss 0.213392 : vld 0.050492
epoch  6 : iter   90 : loss 0.196272 : vld 0.049158
epoch  7 : iter   10 : loss 0.201604 : vld 0.048325
epoch  7 : iter   20 : loss 0.202121 : vld 0.046992
epoch  7 : iter   30 : loss 0.192006 : vld 0.048825
epoch  7 : iter   40 : loss 0.202953 : vld 0.049658
epoch  7 : iter   50 : loss 0.199523 : vld 0.048325
epoch  7 : iter   60 : loss 0.187423 : vld 0.048825
epoch  7 : iter   70 : loss 0.186096 : vld 0.047825
epoch  7 : iter   80 : loss 0.190458 : vld 0.047159
epoch  7 : iter   90 : loss 0.188361 : vld 0.045159
epoch  8 : iter   10 : loss 0.177504 : vld 0.042326
epoch  8 : iter   20 : loss 0.192348 : vld 0.041826
epoch  8 : iter   30 : loss 0.189497 : vld 0.043993
epoch  8 : iter   40 : loss 0.177797 : vld 0.041993
epoch  8 : iter   50 : loss 0.173318 : vld 0.043159
epoch  8 : iter   60 : loss 0.180052 : vld 0.041660
epoch  8 : iter   70 : loss 0.196693 : vld 0.042326
epoch  8 : iter   80 : loss 0.189424 : vld 0.039993
epoch  8 : iter   90 : loss 0.175554 : vld 0.042326
epoch  9 : iter   10 : loss 0.166158 : vld 0.040327
epoch  9 : iter   20 : loss 0.170383 : vld 0.040827
epoch  9 : iter   30 : loss 0.177975 : vld 0.038160
epoch  9 : iter   40 : loss 0.182315 : vld 0.038994
epoch  9 : iter   50 : loss 0.172291 : vld 0.037994
epoch  9 : iter   60 : loss 0.171315 : vld 0.037160
epoch  9 : iter   70 : loss 0.170405 : vld 0.038494
epoch  9 : iter   80 : loss 0.165823 : vld 0.037660
epoch  9 : iter   90 : loss 0.184017 : vld 0.038994
epoch 10 : iter   10 : loss 0.159444 : vld 0.036494
epoch 10 : iter   20 : loss 0.167838 : vld 0.036994
epoch 10 : iter   30 : loss 0.162894 : vld 0.038994
