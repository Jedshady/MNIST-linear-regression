###########################################
#epoch number: 100
#minibatch size: 120
#precision type: full precision
#training mode: multi workers
#gradients update rule: BM_Scale_Momentum_Decay
###########################################
epoch  1 : iter   10 : loss 1.828670 : vld 0.208799
epoch  1 : iter   20 : loss 0.647442 : vld 0.128312
epoch  1 : iter   30 : loss 0.455963 : vld 0.114148
epoch  1 : iter   40 : loss 0.430617 : vld 0.099483
epoch  1 : iter   50 : loss 0.380280 : vld 0.089652
epoch  1 : iter   60 : loss 0.350007 : vld 0.083986
epoch  1 : iter   70 : loss 0.326848 : vld 0.081486
epoch  1 : iter   80 : loss 0.329902 : vld 0.077487
epoch  1 : iter   90 : loss 0.311849 : vld 0.079487
epoch  2 : iter   10 : loss 0.310562 : vld 0.066822
epoch  2 : iter   20 : loss 0.283320 : vld 0.070655
epoch  2 : iter   30 : loss 0.282982 : vld 0.071155
epoch  2 : iter   40 : loss 0.316412 : vld 0.060823
epoch  2 : iter   50 : loss 0.265741 : vld 0.057324
epoch  2 : iter   60 : loss 0.269483 : vld 0.055491
epoch  2 : iter   70 : loss 0.237693 : vld 0.052158
epoch  2 : iter   80 : loss 0.235934 : vld 0.057324
epoch  2 : iter   90 : loss 0.255363 : vld 0.051491
epoch  3 : iter   10 : loss 0.232425 : vld 0.046159
epoch  3 : iter   20 : loss 0.231020 : vld 0.048159
epoch  3 : iter   30 : loss 0.229912 : vld 0.045826
epoch  3 : iter   40 : loss 0.210581 : vld 0.049325
epoch  3 : iter   50 : loss 0.229993 : vld 0.044493
epoch  3 : iter   60 : loss 0.218513 : vld 0.046326
epoch  3 : iter   70 : loss 0.212806 : vld 0.048825
epoch  3 : iter   80 : loss 0.220301 : vld 0.045826
epoch  3 : iter   90 : loss 0.197000 : vld 0.045326
epoch  4 : iter   10 : loss 0.192721 : vld 0.039993
epoch  4 : iter   20 : loss 0.189435 : vld 0.042493
epoch  4 : iter   30 : loss 0.207691 : vld 0.043493
epoch  4 : iter   40 : loss 0.200002 : vld 0.042326
epoch  4 : iter   50 : loss 0.196248 : vld 0.041326
epoch  4 : iter   60 : loss 0.195387 : vld 0.041826
epoch  4 : iter   70 : loss 0.194036 : vld 0.041993
epoch  4 : iter   80 : loss 0.199978 : vld 0.044826
epoch  4 : iter   90 : loss 0.202245 : vld 0.040493
epoch  5 : iter   10 : loss 0.168250 : vld 0.038660
epoch  5 : iter   20 : loss 0.178842 : vld 0.037327
epoch  5 : iter   30 : loss 0.192245 : vld 0.036994
epoch  5 : iter   40 : loss 0.175598 : vld 0.037994
epoch  5 : iter   50 : loss 0.186713 : vld 0.038494
epoch  5 : iter   60 : loss 0.186235 : vld 0.036994
epoch  5 : iter   70 : loss 0.183799 : vld 0.037494
epoch  5 : iter   80 : loss 0.166113 : vld 0.034994
epoch  5 : iter   90 : loss 0.173929 : vld 0.037160
epoch  6 : iter   10 : loss 0.161021 : vld 0.033494
epoch  6 : iter   20 : loss 0.165379 : vld 0.034661
epoch  6 : iter   30 : loss 0.179203 : vld 0.031828
epoch  6 : iter   40 : loss 0.160282 : vld 0.038327
epoch  6 : iter   50 : loss 0.163492 : vld 0.034994
epoch  6 : iter   60 : loss 0.166102 : vld 0.039493
epoch  6 : iter   70 : loss 0.169702 : vld 0.037994
epoch  6 : iter   80 : loss 0.173152 : vld 0.036327
epoch  6 : iter   90 : loss 0.178063 : vld 0.037994
epoch  7 : iter   10 : loss 0.158252 : vld 0.034994
epoch  7 : iter   20 : loss 0.166182 : vld 0.035661
epoch  7 : iter   30 : loss 0.160747 : vld 0.032328
epoch  7 : iter   40 : loss 0.153828 : vld 0.031995
epoch  7 : iter   50 : loss 0.178233 : vld 0.030995
epoch  7 : iter   60 : loss 0.164591 : vld 0.030995
epoch  7 : iter   70 : loss 0.156338 : vld 0.038160
epoch  7 : iter   80 : loss 0.172705 : vld 0.033994
epoch  7 : iter   90 : loss 0.182176 : vld 0.032328
epoch  8 : iter   10 : loss 0.156067 : vld 0.031828
epoch  8 : iter   20 : loss 0.159915 : vld 0.029495
epoch  8 : iter   30 : loss 0.157806 : vld 0.032495
epoch  8 : iter   40 : loss 0.167576 : vld 0.032495
epoch  8 : iter   50 : loss 0.180175 : vld 0.033494
epoch  8 : iter   60 : loss 0.156838 : vld 0.031661
epoch  8 : iter   70 : loss 0.165367 : vld 0.029995
epoch  8 : iter   80 : loss 0.163621 : vld 0.032661
epoch  8 : iter   90 : loss 0.172600 : vld 0.031495
epoch  9 : iter   10 : loss 0.155176 : vld 0.031495
epoch  9 : iter   20 : loss 0.154078 : vld 0.033828
epoch  9 : iter   30 : loss 0.156295 : vld 0.036661
epoch  9 : iter   40 : loss 0.163754 : vld 0.031661
epoch  9 : iter   50 : loss 0.172201 : vld 0.033661
epoch  9 : iter   60 : loss 0.174934 : vld 0.034828
epoch  9 : iter   70 : loss 0.171075 : vld 0.033161
epoch  9 : iter   80 : loss 0.176505 : vld 0.033328
epoch  9 : iter   90 : loss 0.162729 : vld 0.032828
epoch 10 : iter   10 : loss 0.156772 : vld 0.030328
epoch 10 : iter   20 : loss 0.172796 : vld 0.027162
epoch 10 : iter   30 : loss 0.164737 : vld 0.026496
epoch 10 : iter   40 : loss 0.171387 : vld 0.029328
epoch 10 : iter   50 : loss 0.153460 : vld 0.024496
